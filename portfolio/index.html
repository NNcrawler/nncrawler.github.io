<!doctype html><html lang=en><head><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=stylesheet href=/fonts/fonts.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@500;600&family=Space+Grotesk:wght@600;700&display=swap"><link rel=stylesheet href=/css/main.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-WKCSK8TQ4L"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WKCSK8TQ4L")}</script><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>rasyidhakim.com</title><script src=/dist/web-components.umd.js></script><script>window.customElements||document.write('<script src="https://unpkg.com/@webcomponents/webcomponentsjs@^2/webcomponents-loader.js"><\/script>')</script></head><body><div class=site-frame><div class="site-frame__inner site-frame__inner--list surface--page"><div class=list-page__header><h1 class=list-page__title>portfolio.</h1><p class=list-page__subtitle>Showcase of my craft.</p></div><div class=portfolio-intro><div class=portfolio-intro__row><p class=portfolio-intro__wisdom>Crafting strong systems requires skill â€” and skill comes from hard-won experience</p><div class=portfolio-intro__parts><p class=portfolio-intro__label>Used programming language</p><p class=portfolio-intro__value><b id=languages>JavaScript, Golang, Java, Clojure, Ruby, Python</b></p><script type=module>
    import Typed from 'https://esm.sh/typed.js@2.0.12';

    function typeEffect(elId) {
        const vals = document.getElementById(elId).textContent.split(', ')
        document.getElementById(elId).textContent = ''
        var typed = new Typed(`#${elId}`, {
            strings: vals,
            typeSpeed: 50,
            loop: true
        });
    }

    typeEffect("languages")

</script><p class=portfolio-intro__label>Built systems on top of</p><p class=portfolio-intro__value><b id=platforms>Apache Flink, Apache Kafka, Websocket, Rest, BigQuery, PostgreSQL, React, Kubernetes, Terraform, GCP, MaxCompute</b></p><script type=module>
    import Typed from 'https://esm.sh/typed.js@2.0.12';

    function typeEffect(elId) {
        const vals = document.getElementById(elId).textContent.split(', ')
        document.getElementById(elId).textContent = ''
        var typed = new Typed(`#${elId}`, {
            strings: vals,
            typeSpeed: 50,
            loop: true
        });
    }

    typeEffect("platforms")

</script><p class=portfolio-intro__label>Systems I've crafted</p><p class=portfolio-intro__value><b id=systems>Web UI, Data Ingestion, Analytics, ETL, Deployment solution, Streaming Engine</b></p><script type=module>
    import Typed from 'https://esm.sh/typed.js@2.0.12';

    function typeEffect(elId) {
        const vals = document.getElementById(elId).textContent.split(', ')
        document.getElementById(elId).textContent = ''
        var typed = new Typed(`#${elId}`, {
            strings: vals,
            typeSpeed: 50,
            loop: true
        });
    }

    typeEffect("systems")

</script></div></div></div><section class=portfolio-metrics><div class=portfolio-metrics__row><div class=portfolio-metrics__item><p class=portfolio-metrics__value>7+</p><p class=portfolio-metrics__label>Years in Engineering</p></div><div class=portfolio-metrics__item><p class=portfolio-metrics__value>3 Mio +</p><p class=portfolio-metrics__label>Of Dollars Saved From Successful Projects</p></div><div class=portfolio-metrics__item><p class=portfolio-metrics__value>50+</p><p class=portfolio-metrics__label>People Mentored</p></div></div></section><div class=portfolio-orgs><div class=portfolio-orgs__row><img class=portfolio-orgs__logo src=/portfolio/raystack.webp alt=raystack>
<img class=portfolio-orgs__logo src=/portfolio/goto.webp alt=goto>
<img class=portfolio-orgs__logo src=/portfolio/yabb.webp alt=yabb>
<img class=portfolio-orgs__logo src=/portfolio/purwadhika.webp alt=purwadhika></div><p class=portfolio-orgs__caption>organizations where I honed my craft as engineer and mentor</p></div><section class=portfolio-experience><div class=portfolio-experience__group><div class=portfolio-experience__grid><div class=portfolio-experience__overview><div class=portfolio-experience__heading><h1 id=data-streaming-platform class=portfolio-experience__system>Data Streaming Platform</h1><button onclick='const id="data-streaming-platform",url=location.origin+location.pathname+"#"+id;navigator.clipboard.writeText(url),history.replaceState(null,"","#"+id)' class=portfolio-experience__anchor title="Copy link to this section" aria-label="Copy link to Data Streaming Platform">
ðŸ”—</button></div><div class="portfolio-experience__description prose"><p>In an organization that heavily adopts Apache Kafka and event-driven architecture, Kafka events become a critical asset â€” enabling the development of various applications that react to real-time data.</p><p>However, not every developer wants or needs to interact with Kafka directly. To make Kafka more accessible and unlock its full potential across the organization, we built a platform called Firehose.</p><p>Firehose simplifies Kafka consumption by exposing events through a familiar interface: HTTP webhooks. Developers can use a self-serve UI to select the Kafka events they want to subscribe to, and Firehose will automatically deliver those events to their configured webhook endpoint. It also handles scaling, monitoring, and lifecycle management out of the box â€” all self-serve from the UI.</p><p>While Firehose empowers teams to consume events using their own logic, we also built Dagger â€” a no-code stream processing platform. With Dagger, developers can transform Kafka events using SQL, without writing or deploying custom application code. Dagger powers many critical systems, including supply-demand aggregation for surge pricing, fraud detection, and ad impression pipelines â€” all through declarative SQL, without the overhead of managing services.</p></div></div><div class=portfolio-experience__cards><v1-filter-in class=portfolio-experience__filter><div class="card portfolio-work-card" data-filter='{"complexity": "low", "Tech & Tools": ["Java","Apache Flink","Apache Kafka"] }'><span class="portfolio-work-card__badge complexity--low" title="low complexity">ã€¡
<span class=portfolio-work-card__tooltip>low complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>Real-Time Fraud Detection Migration Support</h2><p class=portfolio-work-card__stack>[Java Apache Flink Apache Kafka]</p><p class=portfolio-work-card__description>Migrated fraud detection rules from batch to stream processing, enabling immediate fraud detection through Apache Flink. Improved system responsiveness and detection accuracy.</p></div></div><div class="card portfolio-work-card" data-filter='{"complexity": "mid", "Tech & Tools": ["Nodejs","Javascript"] }'><span class="portfolio-work-card__badge complexity--mid" title="mid complexity">ã€¢
<span class=portfolio-work-card__tooltip>mid complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>One-Click Deployment Solution</h2><p class=portfolio-work-card__stack>[Nodejs Javascript]</p><p class=portfolio-work-card__description>Developed a one-click deployment tool to simplify and streamline application release workflows, reducing manual steps and improving developer productivity.</p></div></div><div class="card portfolio-work-card" data-filter='{"complexity": "mid", "Tech & Tools": ["Java","Apache Flink","Kafka"] }'><span class="portfolio-work-card__badge complexity--mid" title="mid complexity">ã€¢
<span class=portfolio-work-card__tooltip>mid complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>Stream Processing Platform Enhancements</h2><p class=portfolio-work-card__stack>[Java Apache Flink Kafka]</p><p class=portfolio-work-card__description>Maintained and extended a Flink-based stream processing platform. Developed custom UDFs and introduced long-window aggregation support to meet complex analytics needs.</p></div></div><div class="card portfolio-work-card" data-filter='{"complexity": "mid", "Tech & Tools": ["Telegraf","Influx","Grafana"] }'><span class="portfolio-work-card__badge complexity--mid" title="mid complexity">ã€¢
<span class=portfolio-work-card__tooltip>mid complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>Firehose Monitoring Improvements</h2><p class=portfolio-work-card__stack>[Telegraf Influx Grafana]</p><p class=portfolio-work-card__description>Improved observability of Firehose by enhancing monitoring and metrics collection. Enabled better support for multiple sinks through Telegraf and InfluxDB instrumentation.</p></div></div></v1-filter-in></div></div></div><div class=portfolio-experience__group><div class=portfolio-experience__grid><div class=portfolio-experience__overview><div class=portfolio-experience__heading><h1 id=clickstream-ingestion class=portfolio-experience__system>Clickstream Ingestion</h1><button onclick='const id="clickstream-ingestion",url=location.origin+location.pathname+"#"+id;navigator.clipboard.writeText(url),history.replaceState(null,"","#"+id)' class=portfolio-experience__anchor title="Copy link to this section" aria-label="Copy link to Clickstream Ingestion">
ðŸ”—</button></div><div class="portfolio-experience__description prose"><p>Clickstream data is essential for marketing analytics and product development. However, collecting and managing this data presents several challenges. The ingestion system must be scalable to handle the high volume of user-generated events. It must also support flexible schemas to accommodate variations across event types. Additionally, the high frequency of incoming data requires careful selection of the communication protocol to ensure efficiency.</p><p>To address these challenges, we developed a clickstream ingestion platform called Raccoon.</p><p>Raccoon is a horizontally scalable, Go-based service that ingests clickstream data over the WebSocket protocol. It receives events from clients and routes them to Kafka topics for downstream processing. Built for scale and flexibility, Raccoon became the foundation for Gojekâ€™s internal clickstream pipeline â€” enabling the company to replace a third-party SaaS solution that previously cost over $5 million USD annually.</p></div></div><div class=portfolio-experience__cards><v1-filter-in class=portfolio-experience__filter><div class="card portfolio-work-card" data-filter='{"complexity": "high", "Tech & Tools": ["Go","WebSocket","Apache Kafka"] }'><span class="portfolio-work-card__badge complexity--high" title="high complexity">ã€£
<span class=portfolio-work-card__tooltip>high complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>Raccoon implementation</h2><p class=portfolio-work-card__stack>[Go WebSocket Apache Kafka]</p><p class=portfolio-work-card__description>Developed a Go-based ingestion service to collect clickstream data via WebSocket and forward it to Kafka. Built according to a technical RFC and designed to scale for petabytes of daily traffic per data partition. Later extended to support additional protocols.</p></div></div><div class="card portfolio-work-card" data-filter='{"complexity": "mid", "Tech & Tools": ["Go","Kafka","WebSocket"] }'><span class="portfolio-work-card__badge complexity--mid" title="mid complexity">ã€¢
<span class=portfolio-work-card__tooltip>mid complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>Open-Source Raccoon</h2><p class=portfolio-work-card__stack>[Go Kafka WebSocket]</p><p class=portfolio-work-card__description>Open-sourced the Mercury ingestion service as [Raccoon](https://github.com/goto/raccoon), enabling broader community use for scalable event ingestion. Contributed to documentation, production hardening, and feature generalization to support various protocols.</p></div></div></v1-filter-in></div></div></div><div class=portfolio-experience__group><div class=portfolio-experience__grid><div class=portfolio-experience__overview><div class=portfolio-experience__heading><h1 id=customer-segmentation-engine class=portfolio-experience__system>Customer Segmentation Engine</h1><button onclick='const id="customer-segmentation-engine",url=location.origin+location.pathname+"#"+id;navigator.clipboard.writeText(url),history.replaceState(null,"","#"+id)' class=portfolio-experience__anchor title="Copy link to this section" aria-label="Copy link to Customer Segmentation Engine">
ðŸ”—</button></div><div class="portfolio-experience__description prose"><p>Being able to define customer segments based on user behavior and attributes is essential for effective marketing. Traditionally, creating these segments requires marketers to identify data sources, write SQL queries, and manually execute them â€” a process that is tedious, error-prone, and time-consuming.</p><p>To remove this burden, we developed the Customer Segmentation Engine â€” a system that enables marketers to define segments declaratively based on customer properties and past behaviors, without writing SQL. Once defined, a segment can be executed to generate a list of customers who match the criteria. Segment definitions are reusable and can be saved for future campaigns, allowing marketers to focus on evaluation and optimization rather than data wrangling.</p><p>The engine accepts a segment definition in JSON format. When executed, it compiles the definition into SQL, runs the query, and prepares the result as downloadable CSV files. The engine supports complex logic including nested conditions, logical operators, time-based user behavior filters, and inclusion/exclusion rules.</p><p>This system has become a foundational tool for segmentation across the organization, saving hundreds of hours in manual effort and significantly accelerating campaign execution.</p></div></div><div class=portfolio-experience__cards><v1-filter-in class=portfolio-experience__filter><div class="card portfolio-work-card" data-filter='{"complexity": "high", "Tech & Tools": ["Golang","PostgreSQL","BigQuery"] }'><span class="portfolio-work-card__badge complexity--high" title="high complexity">ã€£
<span class=portfolio-work-card__tooltip>high complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>Rule-Based User Segmentation Engine</h2><p class=portfolio-work-card__stack>[Golang PostgreSQL BigQuery]</p><p class=portfolio-work-card__description>Designed and developed a scalable user segmentation engine to power marketing use cases. Replaced a 3rd-party tool, resulting in millions of dollars in annual savings.</p></div></div></v1-filter-in></div></div></div><div class=portfolio-experience__group><div class=portfolio-experience__grid><div class=portfolio-experience__overview><div class=portfolio-experience__heading><h1 id=clickstream-analytics-redesign class=portfolio-experience__system>Clickstream Analytics Redesign</h1><button onclick='const id="clickstream-analytics-redesign",url=location.origin+location.pathname+"#"+id;navigator.clipboard.writeText(url),history.replaceState(null,"","#"+id)' class=portfolio-experience__anchor title="Copy link to this section" aria-label="Copy link to Clickstream Analytics Redesign">
ðŸ”—</button></div><div class="portfolio-experience__description prose"><p>An internal platform was developed to support analytics on top of clickstream data, primarily for product analytics. It allowed users to visualize trends, build dashboards, browse a catalog of clickstream events, and trace individual user activity.</p><p>While the platform had some adoption, it suffered from critical issues:</p><ul><li>Trend data was often inaccurate and stale.</li><li>The event catalog was frequently outdated.</li><li>User-level event tracing was extremely slow and frustrating to use.</li><li>The support channel was overwhelmed with complaints and bug reports.
To address these challenges, I led a full system redesign. After the redesign:</li></ul><p>Data accuracy was significantly improved, restoring trust in reported metrics.</p><ul><li>System latency was reduced from minutes to seconds.</li><li>Data freshness is now near real-time.</li><li>The event catalog is automatically and reliably updated.</li><li>Support requests dropped to nearly zero.
The result was a much more stable, performant, and trustworthy platform â€” enabling the product to grow further.</li></ul></div></div><div class=portfolio-experience__cards><v1-filter-in class=portfolio-experience__filter><div class="card portfolio-work-card" data-filter='{"complexity": "high", "Tech & Tools": ["Golang","BigQuery","PostgreSQL"] }'><span class="portfolio-work-card__badge complexity--high" title="high complexity">ã€£
<span class=portfolio-work-card__tooltip>high complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>Analytics Platform Redesign</h2><p class=portfolio-work-card__stack>[Golang BigQuery PostgreSQL]</p><p class=portfolio-work-card__description>Redesigned key features of an internal analytics platform by identifying and resolving performance bottlenecks. Improved performance and significantly reduced operational costs.</p></div></div></v1-filter-in></div></div></div><div class=portfolio-experience__group><div class=portfolio-experience__grid><div class=portfolio-experience__overview><div class=portfolio-experience__heading><h1 id=a/b-testing-platform class=portfolio-experience__system>A/B Testing Platform</h1><button onclick='const id="a/b-testing-platform",url=location.origin+location.pathname+"#"+id;navigator.clipboard.writeText(url),history.replaceState(null,"","#"+id)' class=portfolio-experience__anchor title="Copy link to this section" aria-label="Copy link to A/B Testing Platform">
ðŸ”—</button></div><div class="portfolio-experience__description prose"><p>A/B testing allows product teams to optimize experiences based on data rather than assumptions. To enable this, an internal A/B testing platform was developed.</p><p>The platform provides:</p><ul><li>Remote configuration, allowing teams to control feature behavior without deploying new code.</li><li>Traffic splitting, enabling controlled experimentation across user segments.</li><li>Data collection, where all traffic assignments are logged for downstream analytics and experiment evaluation.</li></ul><p>This platform empowers product managers to run experiments at scale, make data-driven decisions, and iterate quickly based on measurable impact.</p></div></div><div class=portfolio-experience__cards><v1-filter-in class=portfolio-experience__filter><div class="card portfolio-work-card" data-filter='{"complexity": "mid", "Tech & Tools": ["React","Golang"] }'><span class="portfolio-work-card__badge complexity--mid" title="mid complexity">ã€¢
<span class=portfolio-work-card__tooltip>mid complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>UI Revamp Implementation</h2><p class=portfolio-work-card__stack>[React Golang]</p><p class=portfolio-work-card__description>Revamped the UI of an internal A/B testing platform, significantly improving usability and user experience for experiment owners and analysts.</p></div></div><div class="card portfolio-work-card" data-filter='{"complexity": "high", "Tech & Tools": ["Go","BigQuery","PostgreSQL"] }'><span class="portfolio-work-card__badge complexity--high" title="high complexity">ã€£
<span class=portfolio-work-card__tooltip>high complexity</span></span><div class=portfolio-work-card__body><h2 class=portfolio-work-card__title>In-House Experimentat Analytics Platform</h2><p class=portfolio-work-card__stack>[Go BigQuery PostgreSQL]</p><p class=portfolio-work-card__description>Collaborated with the experimentation team to reverse-engineer Eppo and design an in-house experimentation analytics platform. Led system design and oversaw implementation, replacing a third-party solution with a custom architecture tailored to internal needs.</p></div></div></v1-filter-in></div></div></div></section><footer class=site-footer><div><a href=/>HOME</a> | <a href=/blog>BLOG</a> | <a href=/portfolio>PORTFOLIO</a></div>2025 rasyidhakim.com</footer></div></div></body></html>