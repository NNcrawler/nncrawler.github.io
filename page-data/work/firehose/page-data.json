{"componentChunkName":"component---src-templates-work-js","path":"/work/firehose/","result":{"data":{"site":{"siteMetadata":{"title":"Rasyid Hakim"}},"markdownRemark":{"id":"2f67c2b2-3096-53a4-be1b-e4143d08e712","excerpt":"Firehose is a streaming data pipeline to move Protobuf data from Kafka to data stores. Gojek has been using Firehose in production for years before weâ€¦","htmlAst":{"type":"root","children":[{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;"},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/4ed585eb6ea1933f6aaac4e3dd780cab/3996e/high-level.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 57.432432432432435%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABOklEQVQoz5WSTU7DMBCFc18kjsIBEGv2bDgAOxasK1ghUVogfyWNHcdj+zFjp+BGlUgtTWw59uf3ZqbAwhFCyOYA54FeW7Rti7quobWG9x7FMtgx1PsE9PzxZEFEcM4loByaR65qvi+zm4Df2uG1UmibBuqg8BRwDs6HwMgF+AlsyEeFAvvXsuOLI3HYvwcMr8Uyc9CpEZuPMuZQcim2Cz1YrLc1tl8tNp8t+sHDMkiZgKs7g4trhcsbjduHEQPDDkDhO/ZtjIkKrbVJIfGmQM1IGAxFO3JYLj2+EO6fbIzVm0sWbbJrWXlvPBqutCgU8OIq50PUp0c5hxyjKM1zeLogeTVTiOLflmGg5Ryq3R675xUqVth13Tl9eFz5+ECY+lByOPWg/D/Lct6L5LgP9z3eq3WscFmWMY8/nwhfsIK8J8oAAAAASUVORK5CYII='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"high level","title":"high level","src":"/static/4ed585eb6ea1933f6aaac4e3dd780cab/fcda8/high-level.png","srcSet":["/static/4ed585eb6ea1933f6aaac4e3dd780cab/12f09/high-level.png 148w","/static/4ed585eb6ea1933f6aaac4e3dd780cab/e4a3f/high-level.png 295w","/static/4ed585eb6ea1933f6aaac4e3dd780cab/fcda8/high-level.png 590w","/static/4ed585eb6ea1933f6aaac4e3dd780cab/3996e/high-level.png 648w"],"sizes":["(max-width:","590px)","100vw,","590px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Firehose is a streaming data pipeline to move "},{"type":"element","tagName":"a","properties":{"href":"https://developers.google.com/protocol-buffers"},"children":[{"type":"text","value":"Protobuf"}]},{"type":"text","value":" data from "},{"type":"element","tagName":"a","properties":{"href":"https://kafka.apache.org/"},"children":[{"type":"text","value":"Kafka"}]},{"type":"text","value":" to data stores. Gojek has been using Firehose in production for years before we opensourced it. By the time this is written we have over 200 Firehoses deployments running on production. Each Firehose deployment have different configurations and different number of replicas. All those deployments happened with minimal help from the Firehose maintainer. Thanks to the configuration over code approach."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"My contribution to Firehose that I am proud of the most is refactored "},{"type":"element","tagName":"a","properties":{"href":"https://odpf.gitbook.io/firehose/guides/create_firehose#create-an-http-sink"},"children":[{"type":"text","value":"HTTP sink"}]},{"type":"text","value":" and "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/odpf/firehose/blob/main/src/main/java/io/odpf/firehose/sink/AbstractSink.java"},"children":[{"type":"text","value":"abstracted sink lifecycle"}]},{"type":"text","value":". HTTP sink had many adoptions back then. This resulted in features coming in. The problem was, we were focusing only on addition. I saw a room for improvement to refactor it in a more readable and extendible fashion. After the refactor, to add different body payload formats, we only need to create a new body class and add the construction logic to the factory. The second contribution was abstracted sink lifecycle. My "},{"type":"element","tagName":"a","properties":{"href":"https://in.linkedin.com/in/gsinghania"},"children":[{"type":"text","value":"TL"}]},{"type":"text","value":" back then saw pattern in the metrics emitted by Firehose and thought that we can do something about it. He assigned me with the task. After analysis, I proposed an abstracted lifecycle for Sink that contains common metrics like latency. With this change, it provides out-of-the-box metrics when extending sink."}]}],"data":{"quirksMode":false}},"frontmatter":{"title":"ODPF/Firehose","date":"October 16, 2021","description":"Extensible, no-code, and cloud-native service to load real-time streaming data from Kafka to data stores, data lakes, and analytical storage systems.","category":"Data Pipeline","demo":null,"github":"https://github.com/odpf/firehose"}}},"pageContext":{"slug":"/firehose/"}}}